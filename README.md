# Papers

## Bese Method
1.  Mixup: [Mixup: Beyond Empirical Risk Minimization](https://arxiv.org/pdf/1710.09412) [2018; CV, Speech, Tabular, GAN, Adversarial Example]
2.  Framework: [Improved Mixed-Example Data Augmentation](https://arxiv.org/pdf/1805.11272.pdf?ref=https://githubhelp.com) [2018; CV]

## Variants
1.  CutMix: [CutMix: Regularization Strategy to Train Strong Classifiers with Localizable Features](https://openaccess.thecvf.com/content_ICCV_2019/papers/Yun_CutMix_Regularization_Strategy_to_Train_Strong_Classifiers_With_Localizable_Features_ICCV_2019_paper.pdf) [2019; CV, Adversarial Example, Uncertainty]
2.  RICAP: [RICAP: Random Image Cropping and Patching Data Augmentation for Deep CNNs](http://proceedings.mlr.press/v95/takahashi18a/takahashi18a.pdf) [2018, CV]

## Others
1.  SamplePairing: [Data Augmentation by Pairing Samples for Images Classification](https://arxiv.org/pdf/1801.02929) [2018; CV]

## Applications
1.  wordMixup & senMixup: [Augmenting Data with Mixup for Sentence Classification: An Empirical Study](https://arxiv.org/pdf/1905.08941.pdf) [2019; NLP]

# Code Repositories
1. BC: https://github.com/mil-tokyo/bc_learning_image
2. [BC](https://github.com/mil-tokyo/bc_learning_image)


## Keys
1.  Number of samples for mixup == 2;
2.  Data Augment v.s. Regularization --> Mixup v.s. Weight Decay;
3.  Why and which specific properties;
4.  Limits;
5.  Order of data augment;